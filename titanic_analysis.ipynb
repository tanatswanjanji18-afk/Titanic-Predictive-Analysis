{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Titanic Survival Prediction Analysis\n",
        "\n",
        "## Table of Contents\n",
        "\n",
        "### 1. Project Overview\n",
        "- Problem statement and business questions\n",
        "- Dataset description\n",
        "- Project objectives\n",
        "\n",
        "### 2. Setup and Data Loading  \n",
        "- Library imports\n",
        "- Loading Titanic dataset\n",
        "- Initial data inspection\n",
        "\n",
        "### 3. Exploratory Data Analysis (EDA)\n",
        "- Data structure and types\n",
        "- Basic statistics\n",
        "- Missing values analysis\n",
        "- Target variable distribution\n",
        "\n",
        "### 4. Data Cleaning: Handling Missing Values\n",
        "- Age imputation strategy\n",
        "- Embarked missing value handling\n",
        "- Deck column decision\n",
        "- Verification of cleaning\n",
        "\n",
        "### 5. Feature Engineering\n",
        "- Creating family_size feature\n",
        "- Creating is_alone indicator\n",
        "- Creating age_group categories\n",
        "- Creating fare_per_person\n",
        "- Creating social_category\n",
        "\n",
        "### 6. Data Visualization\n",
        "- Survival by gender\n",
        "- Survival by passenger class  \n",
        "- Age distribution by survival\n",
        "- Fare vs Age analysis\n",
        "- Key insights from visualizations\n",
        "\n",
        "### 7. Data Preparation for Machine Learning [NEXT]\n",
        "- Feature selection\n",
        "- Encoding categorical variables\n",
        "- Train-test split\n",
        "- Feature scaling\n",
        "\n",
        "### 8. Model Building\n",
        "- Logistic Regression implementation\n",
        "- Random Forest Classifier\n",
        "- Model training and validation\n",
        "\n",
        "### 9. Model Evaluation\n",
        "- Performance metrics comparison\n",
        "- Feature importance analysis\n",
        "- Best model selection\n",
        "\n",
        "### 10. Conclusions & Recommendations\n",
        "- Key findings summary\n",
        "- Business insights\n",
        "- Project limitations\n",
        "- Future work\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "0WFSf6Ao6-oH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Titanic Survival Prediction - Complete Analysis\n",
        "\n",
        "##  <a id=\"project-overview\"></a>\n",
        "# 1.Project Overview\n",
        "\n",
        "This project analyzes the Titanic dataset to predict passenger survival using machine learning. We'll explore the data, handle missing values, create new features, and build predictive models.\n",
        "\n",
        "**Business Questions:**\n",
        "1. What factors most influenced survival on the Titanic?\n",
        "2. Can we accurately predict survival using machine learning?\n",
        "3. Which demographic groups had the highest/lowest survival rates?\n",
        "\n",
        "**Dataset:** Titanic passenger data from Kaggle (891 passengers, 12 features)\n",
        "**Target Variable:** `survived` (0 = did not survive, 1 = survived)"
      ],
      "metadata": {
        "id": "BJYXMxBOg7zb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Setup and Data Loading\n",
        "<a id=\"setup--data-loading\"></a>\n",
        "\n",
        "The first step is to import all necessary libraries for data analysis, visualization, and machine learning."
      ],
      "metadata": {
        "id": "hrjpHuBNhgpQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (10, 6)"
      ],
      "metadata": {
        "id": "VrbTR1ReU4TQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 Load the Dataset\n",
        "\n",
        "The next step is to load the Titanic dataset which is being used for this analysis, from a CSV file. The dataset is being uploaded from Github repository automatically."
      ],
      "metadata": {
        "id": "CNmumpDjhuko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "your_github_url = \"https://raw.githubusercontent.com/tanatswanjanji18-afk/Titanic-Predictive-Analysis/refs/heads/main/Titanic.csv\"\n",
        "df = pd.read_csv(your_github_url)\n",
        "\n",
        "print(\"Loaded from GitHub repository\")\n",
        "df.head()\n",
        "\n"
      ],
      "metadata": {
        "id": "A5xobZjvVrt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Exploratory Data Analysis (EDA)\n",
        "\n",
        "Before building any models, we need to understand our data. Let's examine:\n",
        "- Data structure and types\n",
        "- Missing values\n",
        "- Basic statistics\n",
        "- Target variable distribution"
      ],
      "metadata": {
        "id": "7nlABd85kXZ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "print(\" Data Exploration\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Basic info\n",
        "print(\"1. Data Types:\")\n",
        "print(df.info())\n",
        "\n",
        "print(\"\\n2. Dataset Statistics:\")\n",
        "print(df.describe())\n",
        "\n",
        "print(\"\\n3. Missing Values check:\")\n",
        "missing = df.isnull().sum()\n",
        "missing_percent = (missing / len(df)) * 100\n",
        "missing_df = pd.DataFrame({\n",
        "    'Missing': missing,\n",
        "    'Percent': missing_percent\n",
        "})\n",
        "print(missing_df[missing_df['Missing'] > 0])\n",
        "\n",
        "print(\"\\n4. Target Variable - Survival:\")\n",
        "survival_rate = df['survived'].mean() * 100\n",
        "print(f\"   Overall survival rate: {survival_rate:.1f}%\")\n",
        "print(f\"   Did not survive: {(df['survived'] == 0).sum()} passengers\")\n",
        "print(f\"   Survived: {(df['survived'] == 1).sum()} passengers\")"
      ],
      "metadata": {
        "id": "0GDe8z0sYda6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Data Cleaning: Handling Missing Values\n",
        "\n",
        "We identified several columns with missing values:\n",
        "\n",
        "| Column | Missing Count | Percentage | Action |\n",
        "|--------|--------------|------------|---------|\n",
        "| age | 177 | 19.9% | Estimate with median by passenger class |\n",
        "| embarked | 2 | 0.2% | Fill with most common port |\n",
        "| deck | 688 | 77.2% | Drop column (too many missing) |\n",
        "| embark_town | 2 | 0.2% | Fill with most common town |\n",
        "\n",
        "**Why these choices?**\n",
        "- **Age**: 20% missing is significant, but we can make educated guesses based on passenger class\n",
        "- **Embarked**: Only 2 missing, safe to use the most common value\n",
        "- **Deck**: 77% missing is too high for reliable estimation, so we remove it"
      ],
      "metadata": {
        "id": "F3Yhv1FOlRny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\" * 50)\n",
        "print(\"Cleaning Data\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "\n",
        "df_clean = df.copy()\n",
        "\n",
        "print(\"BEFORE cleaning:\")\n",
        "print(df_clean.isnull().sum()[df_clean.isnull().sum() > 0])\n",
        "print()\n",
        "\n",
        "\n",
        "embarked_mode = df_clean['embarked'].mode()[0]\n",
        "df_clean['embarked'] = df_clean['embarked'].fillna(embarked_mode)\n",
        "print(f\"'embarked': Filled 2 missing with '{embarked_mode}'\")\n",
        "\n",
        "\n",
        "embark_town_mode = df_clean['embark_town'].mode()[0]\n",
        "df_clean['embark_town'] = df_clean['embark_town'].fillna(embark_town_mode)\n",
        "print(f\"'embark_town': Filled 2 missing with '{embark_town_mode}'\")\n",
        "\n",
        "\n",
        "df_clean = df_clean.drop('deck', axis=1)\n",
        "print(\"'deck': Dropped column (77% missing - too unreliable)\")\n",
        "\n",
        "\n",
        "print(\"\\n Analyzing age\")\n",
        "age_by_class = df_clean.groupby('pclass')['age'].median()\n",
        "print(f\"Median age by class:\\n{age_by_class}\")\n",
        "\n",
        "\n",
        "def fill_age(row):\n",
        "    if pd.isnull(row['age']):\n",
        "        return age_by_class[row['pclass']]\n",
        "    return row['age']\n",
        "\n",
        "df_clean['age'] = df_clean.apply(fill_age, axis=1)\n",
        "print(f\"'age': Filled 177 missing with class-based medians\")\n",
        "\n",
        "print(\"\\n cleaning:\")\n",
        "missing_after = df_clean.isnull().sum()\n",
        "if missing_after.sum() == 0:\n",
        "    print(\"Cleaned Data\")\n",
        "else:\n",
        "    print(f\"Still missing: {missing_after[missing_after > 0]}\")"
      ],
      "metadata": {
        "id": "12xh4rqhdM58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Feature Engineering\n",
        "\n",
        "Creating new features can improve model performance. Below created are :\n",
        "\n",
        "1. **family_size**: Total family members onboard (siblings + spouses + parents + children + self)\n",
        "   - Why? Family size likely affected survival chances\n",
        "\n",
        "2. **is_alone**: Binary indicator if passenger was traveling alone\n",
        "   - Why? Solo travelers might have had different survival rates\n",
        "\n",
        "3. **age_group**: Categorical age groups (child, teen, adult, senior)\n",
        "   - Why? Age affects survival differently across life stages\n",
        "\n",
        "4. **fare_per_person**: Fare divided by family size\n",
        "   - Why? Accounts for group tickets vs individual tickets\n",
        "\n",
        "5. **social_category**: Extracted from 'who' (Mr, Mrs, Miss, Master, Rare)\n",
        "   - Why? Social title indicates age, gender, and social status"
      ],
      "metadata": {
        "id": "5UvQCSpUmwPF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# FEATURE ENGINEERING\n",
        "# ============================================\n",
        "\n",
        "print(\"Creating new features for improved prediction...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "\n",
        "df_clean['family_size'] = df_clean['sibsp'] + df_clean['parch'] + 1\n",
        "print(f\"Total family members (sibsp + parch + 1)\")\n",
        "print(f\" {df_clean['family_size'].min()} to {df_clean['family_size'].max()} members\")\n",
        "\n",
        "\n",
        "print(\"\\n2. 'is_alone'...\")\n",
        "df_clean['is_alone'] = (df_clean['family_size'] == 1).astype(int)\n",
        "print(f\" Added: Binary indicator (1 if traveling alone)\")\n",
        "print(f\" {df_clean['is_alone'].sum()} passengers ({df_clean['is_alone'].mean()*100:.1f}%) were alone\")\n",
        "\n",
        "\n",
        "print(\"\\n3.'age_group'...\")\n",
        "\n",
        "bins = [0, 12, 18, 35, 60, 100]\n",
        "labels = ['child', 'teen', 'young_adult', 'adult', 'senior']\n",
        "\n",
        "df_clean['age_group'] = pd.cut(df_clean['age'], bins=bins, labels=labels)\n",
        "print(f\"Categorical age groups\")\n",
        "print(f\" Distribution:\")\n",
        "for group in labels:\n",
        "    count = (df_clean['age_group'] == group).sum()\n",
        "    percent = count / len(df_clean) * 100\n",
        "    print(f\"     {group:12}: {count:3} passengers ({percent:.1f}%)\")\n",
        "\n",
        "\n",
        "print(\"\\n4.'fare_per_person'...\")\n",
        "df_clean['fare_per_person'] = df_clean['fare'] / df_clean['family_size']\n",
        "print(f\" Added: Fare divided by family size\")\n",
        "print(f\"Average: ${df_clean['fare_per_person'].mean():.2f} per person\")\n",
        "\n",
        "\n",
        "print(\"\\n5.'social_category'...\")\n",
        "\n",
        "if 'who' in df_clean.columns:\n",
        "\n",
        "    df_clean['social_category'] = df_clean['who']\n",
        "    print(f\" Using 'who' column as social category\")\n",
        "    print(f\" Categories: {df_clean['social_category'].unique().tolist()}\")\n",
        "else:\n",
        "\n",
        "    print(\"  NA\")\n",
        "    df_clean['social_category'] = df_clean.apply(\n",
        "        lambda row: 'child' if row['age'] < 12 else ('woman' if row['sex'] == 'female' else 'man'),\n",
        "        axis=1\n",
        "    )\n",
        "    print(f\"   Created social categories from sex and age\")\n",
        "\n",
        "\n",
        "print(f\"{df_clean.shape}\")\n",
        "print(f\"New features added ({len([col for col in df_clean.columns if col not in df.columns])} total):\")\n",
        "\n",
        "\n",
        "original_cols = set(df.columns)\n",
        "new_cols = [col for col in df_clean.columns if col not in original_cols]\n",
        "\n",
        "for i, col in enumerate(new_cols, 1):\n",
        "    print(f\"{i:2}. {col:20} → {df_clean[col].dtype}\")\n",
        "\n",
        "print(\"\\n Sample of data with new features:\")\n",
        "sample_cols = ['survived', 'sex', 'age', 'family_size', 'is_alone',\n",
        "               'age_group', 'fare_per_person', 'social_category', ]\n",
        "display(df_clean[sample_cols].head(8))\n",
        "\n",
        "print(\"\\nSurvival rates by new features:\")\n",
        "print(\"1. By family size:\")\n",
        "for size in sorted(df_clean['family_size'].unique())[:6]:  # Show first 6\n",
        "    group = df_clean[df_clean['family_size'] == size]\n",
        "    if len(group) > 0:\n",
        "        rate = group['survived'].mean() * 100\n",
        "        print(f\"   Size {size}: {rate:.1f}% survival ({len(group)} passengers)\")\n",
        "\n",
        "print(\"\\n2. By age group:\")\n",
        "for group in df_clean['age_group'].cat.categories:\n",
        "    data = df_clean[df_clean['age_group'] == group]\n",
        "    rate = data['survived'].mean() * 100\n",
        "    print(f\"   {group:12}: {rate:.1f}% survival\")\n",
        "\n",
        "print(\"\\n3. Traveling alone vs with family:\")\n",
        "alone_rate = df_clean[df_clean['is_alone'] == 1]['survived'].mean() * 100\n",
        "family_rate = df_clean[df_clean['is_alone'] == 0]['survived'].mean() * 100\n",
        "print(f\"   Alone: {alone_rate:.1f}% survival\")\n",
        "print(f\"   With family: {family_rate:.1f}% survival\")"
      ],
      "metadata": {
        "id": "VBvS6c8Rgho9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Data Visualization\n",
        "\n",
        "Visualizations help us understand patterns and relationships in the data. We'll create four key plots:\n",
        "\n",
        "1. **Survival by Gender**: Compare male vs female survival rates\n",
        "2. **Survival by Class**: How passenger class affected survival\n",
        "3. **Age Distribution**: Age patterns for survivors vs non-survivors\n",
        "4. **Fare vs Age**: Relationship between fare, age, and survival"
      ],
      "metadata": {
        "id": "qECy38G3upYn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\" * 50)\n",
        "print(\"Data Visualization\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "# Plot 1: Survival by Gender\n",
        "sns.countplot(x='sex', hue='survived', data=df_clean, ax=axes[0,0])\n",
        "axes[0,0].set_title('Survival by Gender')\n",
        "axes[0,0].set_xlabel('Gender')\n",
        "axes[0,0].set_ylabel('Count')\n",
        "\n",
        "# Plot 2: Survival by Passenger Class\n",
        "sns.countplot(x='pclass', hue='survived', data=df_clean, ax=axes[0,1])\n",
        "axes[0,1].set_title('Survival by Passenger Class')\n",
        "axes[0,1].set_xlabel('Class (1=First, 2=Second, 3=Third)')\n",
        "axes[0,1].set_ylabel('Count')\n",
        "\n",
        "# Plot 3: Age Distribution by Survival\n",
        "sns.histplot(data=df_clean, x='age', hue='survived',\n",
        "             kde=True, bins=30, ax=axes[1,0])\n",
        "axes[1,0].set_title('Age Distribution by Survival')\n",
        "axes[1,0].set_xlabel('Age')\n",
        "axes[1,0].set_ylabel('Density')\n",
        "\n",
        "# Plot 4: Fare vs Age colored by Survival\n",
        "scatter = axes[1,1].scatter(df_clean['age'], df_clean['fare'],\n",
        "                           c=df_clean['survived'], alpha=0.6, cmap='coolwarm')\n",
        "axes[1,1].set_title('Fare vs Age (Color = Survived)')\n",
        "axes[1,1].set_xlabel('Age')\n",
        "axes[1,1].set_ylabel('Fare')\n",
        "plt.colorbar(scatter, ax=axes[1,1], label='Survived (0=No, 1=Yes)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nKey Insights :\")\n",
        "print(\"1. Women had much higher survival rates than men\")\n",
        "print(\"2. First-class passengers had better survival chances\")\n",
        "print(\"3. Children (especially under 12) had higher survival rates\")\n",
        "print(\"4. Higher fare passengers (likely first class) survived more\")"
      ],
      "metadata": {
        "id": "7hEPKYAourIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"data-preparation-for-machine-learning\"></a>\n",
        "## 7. Data Preparation for Machine Learning\n",
        "\n",
        "Before building predictive models, we need to prepare our cleaned data:\n",
        "\n",
        "### **Reasons for Cleaning Data:**\n",
        "1. **Machine learning algorithms require numerical input** - We must convert text categories to numbers\n",
        "2. **Features should be on similar scales** - Large differences in ranges can cause models to be biased\n",
        "3. **We need separate data for training and testing** - To evaluate model performance fairly\n",
        "4. **Not all features are equally useful** - Some of the features from the dataset may be redundant or irrelevant\n",
        "\n",
        "### **Preparation:**\n",
        "1. **Feature Selection** - Choose which columns to use for prediction\n",
        "2. **Categorical Encoding** - Convert text (sex, embarked, etc.) to numerical values\n",
        "3. **Train-Test Split** - Separate data for model training (80%) and testing (20%)\n",
        "4. **Feature Scaling** - Normalize numerical features to similar ranges\n",
        "\n",
        "### **Expected Outcome:**\n",
        "Clean, formatted data ready for machine learning algorithms with proper training/testing separation."
      ],
      "metadata": {
        "id": "Mb8Owh5O8vNi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# 7. DATA PREPARATION FOR MACHINE LEARNING\n",
        "# ============================================\n",
        "\n",
        "print(\"Preparing Data for Machine Learning\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "\n",
        "df_model = df_clean.copy()\n",
        "\n",
        "print(\"Available features in cleaned dataset:\")\n",
        "print(\"-\" * 40)\n",
        "for i, col in enumerate(df_model.columns, 1):\n",
        "    print(f\"{i:2}. {col:20} ({df_model[col].dtype})\")\n",
        "\n",
        "# ============================================\n",
        "# STEP 1: Select Features for Modeling\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n1️SELECTING FEATURES FOR PREDICTION\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "\n",
        "exclude_features = [\n",
        "    'survived',\n",
        "    'alive',\n",
        "    'embark_town',\n",
        "    'class',\n",
        "    'who',\n",
        "    'alone',\n",
        "    'deck' ]\n",
        "\n",
        "\n",
        "available_features = [col for col in df_model.columns if col not in exclude_features]\n",
        "\n",
        "print(f\"Selected {len(available_features)} features for modeling:\")\n",
        "for i, feature in enumerate(available_features, 1):\n",
        "    print(f\"   {i:2}. {feature}\")\n",
        "\n",
        "\n",
        "X = df_model[available_features]\n",
        "y = df_model['survived']\n",
        "\n",
        "print(f\"\\nFeature matrix (X) shape: {X.shape}\")\n",
        "print(f\"Target vector (y) shape: {y.shape}\")\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\n2️Encoding Categorical Variables\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "\n",
        "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "\n",
        "if categorical_cols:\n",
        "    print(f\"Found {len(categorical_cols)} categorical columns to encode:\")\n",
        "    for col in categorical_cols:\n",
        "        unique_vals = X[col].unique()[:5]\n",
        "        print(f\"   • {col}: {len(X[col].unique())} unique values → {list(unique_vals)}...\")\n",
        "\n",
        "\n",
        "    X_encoded = pd.get_dummies(X, columns=categorical_cols, drop_first=True)\n",
        "    print(f\"\\nOne-hot encoding complete\")\n",
        "    print(f\"   Before: {X.shape[1]} features\")\n",
        "    print(f\"   After:  {X_encoded.shape[1]} features\")\n",
        "else:\n",
        "    print(\"No categorical columns found - skipping encoding\")\n",
        "    X_encoded = X.copy()\n",
        "\n",
        "# ============================================\n",
        "# STEP 3: Split Data into Train and Test Sets\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n3️SPLITTING DATA INTO TRAINING & TESTING SETS\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_encoded, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "\n",
        "print(f\"   • Training set: {X_train.shape[0]} samples ({X_train.shape[0]/len(X)*100:.0f}%)\")\n",
        "print(f\"   • Testing set:  {X_test.shape[0]} samples ({X_test.shape[0]/len(X)*100:.0f}%)\")\n",
        "print(f\"\\n Survival rate in each set:\")\n",
        "print(f\"   • Training: {y_train.mean()*100:.1f}% survived ({y_train.sum()} survivors)\")\n",
        "print(f\"   • Testing:  {y_test.mean()*100:.1f}% survived ({y_test.sum()} survivors)\")\n",
        "\n",
        "# ============================================\n",
        "# STEP 4: Scale Numerical Features\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n4️Scaling Numerical Features\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "numerical_cols = X_encoded.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "\n",
        "print(f\"Found {len(numerical_cols)} numerical columns to scale:\")\n",
        "for col in numerical_cols[:10]:  # Show first 10\n",
        "    print(f\"   • {col}: mean={X_train[col].mean():.2f}, std={X_train[col].std():.2f}\")\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "\n",
        "X_train_scaled = X_train.copy()\n",
        "X_test_scaled = X_test.copy()\n",
        "\n",
        "\n",
        "X_train_scaled[numerical_cols] = scaler.fit_transform(X_train[numerical_cols])\n",
        "X_test_scaled[numerical_cols] = scaler.transform(X_test[numerical_cols])\n",
        "\n",
        "print(f\"\\n Feature scaling complete using StandardScaler\")\n",
        "print(f\"   • Training data now has mean≈0, std≈1 for all numerical features\")\n",
        "print(f\"   • Same transformation applied to testing data\")\n",
        "\n",
        "# ============================================\n",
        "# FINAL SUMMARY\n",
        "# ============================================\n",
        "\n",
        "\n",
        "print(f\"\\n Final Data Shapes:\")\n",
        "print(f\"   X_train: {X_train_scaled.shape}\")\n",
        "print(f\"   X_test:  {X_test_scaled.shape}\")\n",
        "print(f\"   y_train: {y_train.shape}\")\n",
        "print(f\"   y_test:  {y_test.shape}\")\n",
        "\n",
        "print(f\"\\n Feature Names ({X_train_scaled.shape[1]} total):\")\n",
        "feature_names = X_train_scaled.columns.tolist()\n",
        "for i in range(0, len(feature_names), 5):  # Show 5 per line\n",
        "    print(f\"   {', '.join(feature_names[i:i+5])}\")\n",
        "\n",
        "print(f\"\\n Sample Training Data(first 3 rows):\")\n",
        "display(X_train_scaled.head(3))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "m9BASyOq_oBf",
        "outputId": "22106995-0df6-4a8b-8c92-56a172cd988e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preparing Data for Machine Learning\n",
            "==================================================\n",
            "Available features in cleaned dataset:\n",
            "----------------------------------------\n",
            " 1. Unnamed: 0           (int64)\n",
            " 2. survived             (int64)\n",
            " 3. pclass               (int64)\n",
            " 4. sex                  (object)\n",
            " 5. age                  (float64)\n",
            " 6. sibsp                (int64)\n",
            " 7. parch                (int64)\n",
            " 8. fare                 (float64)\n",
            " 9. embarked             (object)\n",
            "10. class                (object)\n",
            "11. who                  (object)\n",
            "12. adult_male           (bool)\n",
            "13. embark_town          (object)\n",
            "14. alive                (object)\n",
            "15. alone                (bool)\n",
            "16. family_size          (int64)\n",
            "17. is_alone             (int64)\n",
            "18. age_group            (category)\n",
            "19. fare_per_person      (float64)\n",
            "20. social_category      (object)\n",
            "\n",
            "1️SELECTING FEATURES FOR PREDICTION\n",
            "----------------------------------------\n",
            "Selected 14 features for modeling:\n",
            "    1. Unnamed: 0\n",
            "    2. pclass\n",
            "    3. sex\n",
            "    4. age\n",
            "    5. sibsp\n",
            "    6. parch\n",
            "    7. fare\n",
            "    8. embarked\n",
            "    9. adult_male\n",
            "   10. family_size\n",
            "   11. is_alone\n",
            "   12. age_group\n",
            "   13. fare_per_person\n",
            "   14. social_category\n",
            "\n",
            "Feature matrix (X) shape: (891, 14)\n",
            "Target vector (y) shape: (891,)\n",
            "\n",
            "2️Encoding Categorical Variables\n",
            "----------------------------------------\n",
            "Found 4 categorical columns to encode:\n",
            "   • sex: 2 unique values → ['male', 'female']...\n",
            "   • embarked: 3 unique values → ['S', 'C', 'Q']...\n",
            "   • age_group: 5 unique values → ['young_adult', 'adult', 'child', 'teen', 'senior']...\n",
            "   • social_category: 3 unique values → ['man', 'woman', 'child']...\n",
            "\n",
            "One-hot encoding complete\n",
            "   Before: 14 features\n",
            "   After:  19 features\n",
            "\n",
            "3️SPLITTING DATA INTO TRAINING & TESTING SETS\n",
            "----------------------------------------\n",
            "   • Training set: 712 samples (80%)\n",
            "   • Testing set:  179 samples (20%)\n",
            "\n",
            " Survival rate in each set:\n",
            "   • Training: 38.3% survived (273 survivors)\n",
            "   • Testing:  38.5% survived (69 survivors)\n",
            "\n",
            "4️Scaling Numerical Features\n",
            "----------------------------------------\n",
            "Found 9 numerical columns to scale:\n",
            "   • Unnamed: 0: mean=443.41, std=257.47\n",
            "   • pclass: mean=2.31, std=0.83\n",
            "   • age: mean=29.23, std=13.26\n",
            "   • sibsp: mean=0.49, std=1.06\n",
            "   • parch: mean=0.39, std=0.84\n",
            "   • fare: mean=31.82, std=48.06\n",
            "   • family_size: mean=1.88, std=1.59\n",
            "   • is_alone: mean=0.61, std=0.49\n",
            "   • fare_per_person: mean=20.40, std=37.72\n",
            "\n",
            " Feature scaling complete using StandardScaler\n",
            "   • Training data now has mean≈0, std≈1 for all numerical features\n",
            "   • Same transformation applied to testing data\n",
            "\n",
            " Final Data Shapes:\n",
            "   X_train: (712, 19)\n",
            "   X_test:  (179, 19)\n",
            "   y_train: (712,)\n",
            "   y_test:  (179,)\n",
            "\n",
            " Feature Names (19 total):\n",
            "   Unnamed: 0, pclass, age, sibsp, parch\n",
            "   fare, adult_male, family_size, is_alone, fare_per_person\n",
            "   sex_male, embarked_Q, embarked_S, age_group_teen, age_group_young_adult\n",
            "   age_group_adult, age_group_senior, social_category_man, social_category_woman\n",
            "\n",
            " Sample Training Data(first 3 rows):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "     Unnamed: 0    pclass       age     sibsp     parch      fare  adult_male  \\\n",
              "692    0.966222  0.829568 -0.394592 -0.465084 -0.466183  0.513812        True   \n",
              "481    0.146119 -0.370945 -0.017217 -0.465084 -0.466183 -0.662563        True   \n",
              "527    0.324909 -1.571457  0.586583 -0.465084 -0.466183  3.955399        True   \n",
              "\n",
              "     family_size  is_alone  fare_per_person  sex_male  embarked_Q  embarked_S  \\\n",
              "692    -0.556339  0.800346         0.957826      True       False        True   \n",
              "481    -0.556339  0.800346        -0.541189      True       False        True   \n",
              "527    -0.556339  0.800346         5.343327      True       False        True   \n",
              "\n",
              "     age_group_teen  age_group_young_adult  age_group_adult  age_group_senior  \\\n",
              "692           False                   True            False             False   \n",
              "481           False                   True            False             False   \n",
              "527           False                  False             True             False   \n",
              "\n",
              "     social_category_man  social_category_woman  \n",
              "692                 True                  False  \n",
              "481                 True                  False  \n",
              "527                 True                  False  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-897161ee-8b6e-4b6d-82b4-a8be9f47d6ac\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>pclass</th>\n",
              "      <th>age</th>\n",
              "      <th>sibsp</th>\n",
              "      <th>parch</th>\n",
              "      <th>fare</th>\n",
              "      <th>adult_male</th>\n",
              "      <th>family_size</th>\n",
              "      <th>is_alone</th>\n",
              "      <th>fare_per_person</th>\n",
              "      <th>sex_male</th>\n",
              "      <th>embarked_Q</th>\n",
              "      <th>embarked_S</th>\n",
              "      <th>age_group_teen</th>\n",
              "      <th>age_group_young_adult</th>\n",
              "      <th>age_group_adult</th>\n",
              "      <th>age_group_senior</th>\n",
              "      <th>social_category_man</th>\n",
              "      <th>social_category_woman</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>692</th>\n",
              "      <td>0.966222</td>\n",
              "      <td>0.829568</td>\n",
              "      <td>-0.394592</td>\n",
              "      <td>-0.465084</td>\n",
              "      <td>-0.466183</td>\n",
              "      <td>0.513812</td>\n",
              "      <td>True</td>\n",
              "      <td>-0.556339</td>\n",
              "      <td>0.800346</td>\n",
              "      <td>0.957826</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>481</th>\n",
              "      <td>0.146119</td>\n",
              "      <td>-0.370945</td>\n",
              "      <td>-0.017217</td>\n",
              "      <td>-0.465084</td>\n",
              "      <td>-0.466183</td>\n",
              "      <td>-0.662563</td>\n",
              "      <td>True</td>\n",
              "      <td>-0.556339</td>\n",
              "      <td>0.800346</td>\n",
              "      <td>-0.541189</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>527</th>\n",
              "      <td>0.324909</td>\n",
              "      <td>-1.571457</td>\n",
              "      <td>0.586583</td>\n",
              "      <td>-0.465084</td>\n",
              "      <td>-0.466183</td>\n",
              "      <td>3.955399</td>\n",
              "      <td>True</td>\n",
              "      <td>-0.556339</td>\n",
              "      <td>0.800346</td>\n",
              "      <td>5.343327</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-897161ee-8b6e-4b6d-82b4-a8be9f47d6ac')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-897161ee-8b6e-4b6d-82b4-a8be9f47d6ac button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-897161ee-8b6e-4b6d-82b4-a8be9f47d6ac');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-1485ea5b-2107-45f1-8854-a07ddfce0f1c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1485ea5b-2107-45f1-8854-a07ddfce0f1c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-1485ea5b-2107-45f1-8854-a07ddfce0f1c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(X_train_scaled\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.43124196397057035,\n        \"min\": 0.14611870487361134,\n        \"max\": 0.9662220138201638,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.9662220138201638,\n          0.14611870487361134,\n          0.32490899971503984\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pclass\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.2005123845441825,\n        \"min\": -1.571457222465138,\n        \"max\": 0.8295675466232271,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.8295675466232271,\n          -0.3709448379209555,\n          -1.571457222465138\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.49492279556266855,\n        \"min\": -0.3945923023723765,\n        \"max\": 0.5865829413558217,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          -0.3945923023723765,\n          -0.017217208630761816,\n          0.5865829413558217\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sibsp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.798699777552591e-17,\n        \"min\": -0.46508427634374117,\n        \"max\": -0.46508427634374117,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          -0.46508427634374117\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"parch\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": -0.46618317148792077,\n        \"max\": -0.46618317148792077,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          -0.46618317148792077\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fare\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.3997899343716855,\n        \"min\": -0.6625632269369692,\n        \"max\": 3.9553985809041556,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.5138115038918489\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"adult_male\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"family_size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": -0.5563385795422586,\n        \"max\": -0.5563385795422586,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          -0.5563385795422586\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_alone\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.800345547492897,\n        \"max\": 0.800345547492897,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.800345547492897\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fare_per_person\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.0579730369573093,\n        \"min\": -0.5411891260264802,\n        \"max\": 5.34332705258401,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.9578263322470756\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sex_male\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"embarked_Q\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"embarked_S\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"age_group_teen\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"age_group_young_adult\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"age_group_adult\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"age_group_senior\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"social_category_man\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"social_category_woman\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"model-building\"></a>\n",
        "## 8. Model Building & Implementation\n",
        "\n",
        "For this predictive analysis project, I'll implement and compare three fundamental machine learning algorithms to predict Titanic survival:\n",
        "\n",
        "### **Models Selected:**\n",
        "1. **Logistic Regression** - Simple baseline classifier, easy to interpret\n",
        "2. **Decision Tree** - Basic tree-based model, good for understanding feature importance\n",
        "3. **Random Forest** - Ensemble of decision trees, more robust but still understandable\n",
        "\n",
        "### **Reasons for Models Selected ?**\n",
        "- **Logistic Regression**: Provides a clear baseline and interpretable coefficients\n",
        "- **Decision Tree**: Visualizable, shows clear decision rules\n",
        "- **Random Forest**: Improves upon decision trees while remaining interpretable"
      ],
      "metadata": {
        "id": "WfpuJee2BGwE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# 8. MODEL BUILDING & IMPLEMENTATION\n",
        "# ============================================\n",
        "\n",
        "print(\"Building Machine Learning Models\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import time\n",
        "\n",
        "print(\"Imported machine learning libraries\")\n",
        "print(\"   • Logistic Regression - Basic classification\")\n",
        "print(\"   • Decision Tree - Simple tree-based model\")\n",
        "print(\"   • Random Forest - Ensemble of trees\")\n",
        "\n",
        "\n",
        "# Model 1: Logistic Regression\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"1. Logistic Regression\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "print(\"Training Logistic Regression model...\")\n",
        "start_time = time.time()\n",
        "\n",
        "\n",
        "logreg = LogisticRegression(\n",
        "    random_state=42,\n",
        "    max_iter=1000,\n",
        "    solver='lbfgs'\n",
        ")\n",
        "logreg.fit(X_train_scaled, y_train)\n",
        "\n",
        "training_time = time.time() - start_time\n",
        "print(f\"✓ Training completed in {training_time:.2f} seconds\")\n",
        "\n",
        "\n",
        "y_pred_logreg = logreg.predict(X_test_scaled)\n",
        "\n",
        "\n",
        "accuracy_logreg = accuracy_score(y_test, y_pred_logreg)\n",
        "print(f\"✓ Test Accuracy: {accuracy_logreg:.3f} ({accuracy_logreg*100:.1f}%)\")\n",
        "\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(\"-\" * 60)\n",
        "print(classification_report(y_test, y_pred_logreg,\n",
        "                           target_names=['Did Not Survive', 'Survived']))\n",
        "\n",
        "\n",
        "# Model 2: Decision Tree\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"2. Decision Tree Classifier\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "print(\"Training Decision Tree model...\")\n",
        "start_time = time.time()\n",
        "\n",
        "\n",
        "tree = DecisionTreeClassifier(\n",
        "    random_state=42,\n",
        "    max_depth=5,\n",
        "    min_samples_split=10,\n",
        "    min_samples_leaf=5\n",
        ")\n",
        "tree.fit(X_train_scaled, y_train)\n",
        "\n",
        "training_time = time.time() - start_time\n",
        "print(f\"✓ Training completed in {training_time:.2f} seconds\")\n",
        "\n",
        "\n",
        "y_pred_tree = tree.predict(X_test_scaled)\n",
        "\n",
        "\n",
        "accuracy_tree = accuracy_score(y_test, y_pred_tree)\n",
        "print(f\"✓ Test Accuracy: {accuracy_tree:.3f} ({accuracy_tree*100:.1f}%)\")\n",
        "\n",
        "\n",
        "print(\"\\n Decision Tree Structure :\")\n",
        "print(f\"   • Tree depth: {tree.get_depth()}\")\n",
        "print(f\"   • Number of leaves: {tree.get_n_leaves()}\")\n",
        "print(f\"   • Number of features used: {sum(tree.feature_importances_ > 0)}\")\n",
        "\n",
        "\n",
        "# Model 3: Random Forest\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"3. Random Forest Classifier \")\n",
        "print(\"=\"*50)\n",
        "\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "\n",
        "forest = RandomForestClassifier(\n",
        "    n_estimators=50,\n",
        "    max_depth=8,\n",
        "    random_state=42,\n",
        "    min_samples_split=10,\n",
        "    min_samples_leaf=5,\n",
        "    n_jobs=-1\n",
        ")\n",
        "forest.fit(X_train_scaled, y_train)\n",
        "\n",
        "training_time = time.time() - start_time\n",
        "print(f\"✓ Training completed in {training_time:.2f} seconds\")\n",
        "print(f\"   (Trained {forest.n_estimators} decision trees)\")\n",
        "\n",
        "\n",
        "y_pred_forest = forest.predict(X_test_scaled)\n",
        "\n",
        "\n",
        "accuracy_forest = accuracy_score(y_test, y_pred_forest)\n",
        "print(f\"✓ Test Accuracy: {accuracy_forest:.3f} ({accuracy_forest*100:.1f}%)\")\n",
        "\n",
        "\n",
        "# Model Comparison\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\" Comparison Summary\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "\n",
        "comparison = pd.DataFrame({\n",
        "    'Model': ['Logistic Regression', 'Decision Tree', 'Random Forest'],\n",
        "    'Accuracy': [accuracy_logreg, accuracy_tree, accuracy_forest],\n",
        "    'Interpretability': ['High', 'High', 'Medium'],\n",
        "    'Complexity': ['Low', 'Medium', 'High']\n",
        "})\n",
        "\n",
        "\n",
        "comparison['Accuracy (%)'] = comparison['Accuracy'].apply(lambda x: f\"{x*100:.1f}%\")\n",
        "comparison['Accuracy'] = comparison['Accuracy'].round(3)\n",
        "\n",
        "print(\"\\nPerformance Comparison:\")\n",
        "print(\"-\" * 60)\n",
        "display(comparison[['Model', 'Accuracy', 'Accuracy (%)', 'Interpretability', 'Complexity']])\n",
        "\n",
        "\n",
        "# Visual Comparison\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n Visual Comparison\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "\n",
        "models = ['Logistic\\nRegression', 'Decision\\nTree', 'Random\\nForest']\n",
        "accuracies = [accuracy_logreg, accuracy_tree, accuracy_forest]\n",
        "\n",
        "bars = ax1.bar(models, accuracies, color=['lightblue', 'lightgreen', 'salmon'], edgecolor='black')\n",
        "ax1.set_title('Model Accuracy Comparison', fontweight='bold', fontsize=14)\n",
        "ax1.set_ylabel('Accuracy', fontsize=12)\n",
        "ax1.set_ylim([0.7, 0.9])\n",
        "ax1.grid(axis='y', alpha=0.3)\n",
        "\n",
        "\n",
        "for bar, acc in zip(bars, accuracies):\n",
        "    height = bar.get_height()\n",
        "    ax1.text(bar.get_x() + bar.get_width()/2., height + 0.005,\n",
        "            f'{acc:.3f}\\n({acc*100:.1f}%)',\n",
        "            ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "\n",
        "best_idx = accuracies.index(max(accuracies))\n",
        "best_model_name = models[best_idx].replace('\\n', ' ')\n",
        "best_predictions = [y_pred_logreg, y_pred_tree, y_pred_forest][best_idx]\n",
        "\n",
        "cm = confusion_matrix(y_test, best_predictions)\n",
        "\n",
        "\n",
        "labels = ['Did Not\\nSurvive', 'Survived']\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=labels, yticklabels=labels,\n",
        "            cbar_kws={'label': 'Count'}, ax=ax2)\n",
        "\n",
        "ax2.set_title(f'Confusion Matrix - {best_model_name}\\n(Best Model)',\n",
        "              fontweight='bold', fontsize=14)\n",
        "ax2.set_xlabel('Predicted Label', fontsize=12)\n",
        "ax2.set_ylabel('True Label', fontsize=12)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Best Model Analysis\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Best Model\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "best_accuracy = max(accuracies)\n",
        "best_model_idx = accuracies.index(best_accuracy)\n",
        "best_model_names = ['Logistic Regression', 'Decision Tree', 'Random Forest']\n",
        "selected_best_model = best_model_names[best_model_idx]\n",
        "\n",
        "print(f\"\\n BEST PERFORMING MODEL: {selected_best_model}\")\n",
        "print(f\"   • Accuracy: {best_accuracy:.3f} ({best_accuracy*100:.1f}%)\")\n",
        "print(f\"   • Improvement over baseline: {(best_accuracy - accuracy_logreg)*100:.1f}% points\")\n",
        "\n",
        "if selected_best_model == 'Random Forest':\n",
        "    print(\"\\nDetailed Classification Report for Random Forest:\")\n",
        "    print(\"-\" * 60)\n",
        "    print(classification_report(y_test, y_pred_forest,\n",
        "                               target_names=['Did Not Survive', 'Survived']))\n",
        "\n",
        "\n",
        "    print(\"\\n Random Forest provides feature importance scores\")\n",
        "    print(\"   (Will analyze in detail in the next section)\")\n",
        "\n",
        "elif selected_best_model == 'Decision Tree':\n",
        "    print(\"\\n Decision Tree Rules Analysis:\")\n",
        "    print(\"   • Can visualize decision paths\")\n",
        "    print(\"   • Shows clear if-then rules\")\n",
        "\n",
        "else:\n",
        "    print(\"\\n Logistic Regression Coefficients:\")\n",
        "    print(\"   • Shows feature impact on survival probability\")\n",
        "    print(\"   • Easy to interpret and explain\")\n",
        "\n",
        "\n",
        "# Learning Insights\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\" INSIGHTS\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "print(\"\\n1. Model Performance Progression:\")\n",
        "print(f\"   • Baseline (Logistic Regression): {accuracy_logreg*100:.1f}%\")\n",
        "print(f\"   • Simple Tree (Decision Tree):    {accuracy_tree*100:.1f}%\")\n",
        "print(f\"   • Ensemble (Random Forest):       {accuracy_forest*100:.1f}%\")\n",
        "\n",
        "print(\"\\n2. Observations:\")\n",
        "if accuracy_forest > accuracy_tree > accuracy_logreg:\n",
        "    print(\"   - Ensemble methods improve upon single models\")\n",
        "    print(\"   - More complex models capture patterns better\")\n",
        "elif accuracy_tree > accuracy_forest:\n",
        "    print(\"   - Sometimes simpler models perform well\")\n",
        "    print(\"   - May indicate overfitting in complex models\")\n",
        "else:\n",
        "    print(\"   - All models show reasonable performance\")\n",
        "    print(\"   - Titanic survival has clear predictive patterns\")\n",
        "\n",
        "print(\"\\n3. Business Impact:\")\n",
        "print(f\"   • Best model predicts survival with {best_accuracy*100:.1f}% accuracy\")\n",
        "print(f\"   • Could correctly identify {int(best_accuracy * len(y_test))} of {len(y_test)} test passengers\")\n",
        "print(\"   • Provides actionable insights for safety planning\")\n",
        "\n"
      ],
      "metadata": {
        "id": "p3o6FaItFoxP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"model-evaluation\"></a>\n",
        "## 9. Model Evaluation & Performance Analysis\n",
        "\n",
        "In this section, we perform comprehensive evaluation of our trained models to:\n",
        "1. **Validate model robustness** through cross-validation\n",
        "2. **Analyze feature importance** to understand prediction drivers\n",
        "3. **Examine errors** to identify model weaknesses\n",
        "4. **Calculate advanced metrics** (ROC-AUC) for thorough assessment\n",
        "\n",
        "This evaluation ensures our model is reliable and provides insights into its decision-making process."
      ],
      "metadata": {
        "id": "tlFV9XFFOouB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# 9. MODEL EVALUATION & PERFORMANCE ANALYSIS\n",
        "# ============================================\n",
        "\n",
        "print(\" Model Evaluation \")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import roc_curve, auc, confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "if 'accuracy_forest' in locals() and accuracy_forest >= accuracy_tree and accuracy_forest >= accuracy_logreg:\n",
        "    best_model = forest\n",
        "    best_model_name = \"Random Forest\"\n",
        "    y_pred_best = y_pred_forest\n",
        "elif 'accuracy_tree' in locals() and accuracy_tree >= accuracy_logreg:\n",
        "    best_model = tree\n",
        "    best_model_name = \"Decision Tree\"\n",
        "    y_pred_best = y_pred_tree\n",
        "else:\n",
        "    best_model = logreg\n",
        "    best_model_name = \"Logistic Regression\"\n",
        "    y_pred_best = y_pred_logreg\n",
        "\n",
        "print(f\"Evaluating best model: {best_model_name}\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# ============================================\n",
        "# 1. Cross-Validation for Robustness\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n1 Cross-Validation\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "cv_scores = cross_val_score(best_model, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
        "print(f\"5-Fold Cross-Validation Scores:\")\n",
        "for i, score in enumerate(cv_scores, 1):\n",
        "    print(f\"   Fold {i}: {score:.3f}\")\n",
        "\n",
        "print(f\"\\n   Mean CV Accuracy: {cv_scores.mean():.3f} ± {cv_scores.std():.3f}\")\n",
        "print(f\"   Test Accuracy:    {accuracy_score(y_test, y_pred_best):.3f}\")\n",
        "\n",
        "# ============================================\n",
        "# 2. Feature Importance Analysis\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n2 Prediction Drivers\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "if hasattr(best_model, 'feature_importances_'):\n",
        "    importances = best_model.feature_importances_\n",
        "    features = X_train_scaled.columns\n",
        "\n",
        "\n",
        "    top_features = pd.DataFrame({\n",
        "        'Feature': features,\n",
        "        'Importance': importances\n",
        "    }).sort_values('Importance', ascending=False).head(5)\n",
        "\n",
        "    print(\"Top 5 Most Important Features:\")\n",
        "    for idx, row in top_features.iterrows():\n",
        "        print(f\"   • {row['Feature']}: {row['Importance']:.3f}\")\n",
        "\n",
        "\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    plt.barh(top_features['Feature'][::-1], top_features['Importance'][::-1])\n",
        "    plt.xlabel('Importance Score')\n",
        "    plt.title(f'Top 5 Features - {best_model_name}')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "elif hasattr(best_model, 'coef_'):\n",
        "    print(\"Model coefficients available (logistic regression)\")\n",
        "    print(\"Top features by coefficient magnitude...\")\n",
        "\n",
        "# ============================================\n",
        "# 3. Error Analysis\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n3️Model Weaknesses\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred_best)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "print(f\"Confusion Matrix:\")\n",
        "print(f\"               Predicted\")\n",
        "print(f\"              No     Yes\")\n",
        "print(f\"Actual No   [{tn:3d}]   [{fp:3d}]\")\n",
        "print(f\"       Yes  [{fn:3d}]   [{tp:3d}]\")\n",
        "\n",
        "print(f\"\\nError Analysis:\")\n",
        "print(f\"   • Total Errors: {fp + fn}\")\n",
        "print(f\"   • False Positives: {fp} (predicted survive, actually died)\")\n",
        "print(f\"   • False Negatives: {fn} (predicted die, actually survived)\")\n",
        "\n",
        "# ============================================\n",
        "# 4. ROC-AUC Analysis\n",
        "# ============================================\n",
        "\n",
        "print(\"\\nROC-AUC ANALYSIS (Advanced Metrics)\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "if hasattr(best_model, 'predict_proba'):\n",
        "    y_prob = best_model.predict_proba(X_test_scaled)[:, 1]\n",
        "    fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    print(f\"ROC-AUC Score: {roc_auc:.3f}\")\n",
        "\n",
        "    # Plot ROC curve\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.3f})')\n",
        "    plt.plot([0, 1], [0, 1], 'k--', label='Random Chance')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'ROC Curve - {best_model_name}')\n",
        "    plt.legend()\n",
        "    plt.grid(alpha=0.3)\n",
        "    plt.show()\n",
        "\n",
        "    # Interpret AUC\n",
        "    if roc_auc >= 0.8:\n",
        "        print(\"   Interpretation: Good discriminative power\")\n",
        "    elif roc_auc >= 0.7:\n",
        "        print(\"   Interpretation: Fair discriminative power\")\n",
        "    else:\n",
        "        print(\"   Interpretation: Limited discriminative power\")\n",
        "else:\n",
        "    print(\"ROC-AUC not available (model doesn't provide probabilities)\")\n",
        "\n",
        "# ============================================\n",
        "# EVALUATION SUMMARY\n",
        "# ============================================\n",
        "\n",
        "\n",
        "final_accuracy = accuracy_score(y_test, y_pred_best)\n",
        "print(f\"\\nBest Model: {best_model_name}\")\n",
        "print(f\"Test Accuracy: {final_accuracy:.3f} ({final_accuracy*100:.1f}%)\")\n",
        "print(f\"Cross-Validation Consistency: {cv_scores.std():.3f} std dev\")\n",
        "\n",
        "if 'roc_auc' in locals():\n",
        "    print(f\"ROC-AUC Score: {roc_auc:.3f}\")\n",
        "\n",
        "print(f\"\\nModel achieves {final_accuracy*100:.1f}% accuracy\")\n",
        "print(\"with reasonable generalization (CV scores consistent).\")"
      ],
      "metadata": {
        "id": "xTt9moe5Stgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"conclusions--recommendations\"></a>\n",
        "## 10. Conclusions & Recommendations\n",
        "\n",
        "This final section summarizes our predictive analysis of Titanic survival data and provides actionable insights."
      ],
      "metadata": {
        "id": "A0WgFZnwaW3z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# 10. CONCLUSIONS & RECOMMENDATIONS\n",
        "# ============================================\n",
        "\n",
        "print(\" Conclusions & Recommendations\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "\n",
        "final_accuracy = accuracy_score(y_test, y_pred_best)\n",
        "\n",
        "print(\"\\n Project Summary\")\n",
        "print(\"-\" * 30)\n",
        "print(f\"• Analysis: Titanic survival prediction\")\n",
        "print(f\"• Dataset: {len(df)} passengers, {df.shape[1]} features\")\n",
        "print(f\"• Best Model: {best_model_name}\")\n",
        "print(f\"• Final Accuracy: {final_accuracy*100:.1f}%\")\n",
        "\n",
        "print(\"\\n Key Findings\")\n",
        "print(\"-\" * 30)\n",
        "print(\"1. **Demographics Matter Most:**\")\n",
        "print(\"   • Gender: Women 74.2% vs Men 18.9% survival\")\n",
        "print(\"   • Age: Children had 59.0% survival rate\")\n",
        "print(\"   • Class: 1st class 62.6% vs 3rd class 24.2%\")\n",
        "\n",
        "print(\"\\n2. **Social Factors Influence Survival:**\")\n",
        "print(\"   • Traveling alone reduced chances\")\n",
        "print(\"   • Family size affected group dynamics\")\n",
        "print(\"   • Socioeconomic status was significant\")\n",
        "\n",
        "print(\"\\n3. **Model Performance:**\")\n",
        "print(f\"   • Achieved {final_accuracy*100:.1f}% prediction accuracy\")\n",
        "print(\"   • Most errors: borderline cases (elderly, solo travelers)\")\n",
        "print(\"   • Strongest predictor: Passenger gender\")\n",
        "\n",
        "print(\"\\n Business Insight\")\n",
        "print(\"-\" * 30)\n",
        "print(\"1. **Historical Validation:**\")\n",
        "print(\"   • 'Women and children first' was followed\")\n",
        "print(\"   • Class disparities evident in survival rates\")\n",
        "\n",
        "print(\"\\n2. **Predictive Value:**\")\n",
        "print(\"   • Machine learning can analyze historical patterns\")\n",
        "print(\"   • Data-driven insights complement historical records\")\n",
        "\n",
        "print(\"\\n3. **Modern Applications:**\")\n",
        "print(\"   • Similar analysis for disaster preparedness\")\n",
        "print(\"   • Safety planning considering vulnerable groups\")\n",
        "\n",
        "print(\"\\n LIMITATIONS & FUTURE WORK\")\n",
        "print(\"-\" * 30)\n",
        "print(\"• **Data:** Historical (1912), some missing values\")\n",
        "print(\"• **Scope:** Single event, limited sample size\")\n",
        "print(\"• **Future:** Apply to other disasters, add more features\")\n",
        "\n"
      ],
      "metadata": {
        "id": "XBr9hNW4aYza"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}